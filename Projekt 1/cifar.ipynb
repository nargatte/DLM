{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.metrics.confusion_matrix import ConfusionMatrix\n",
    "from ignite.handlers import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"        # bez tego wysadza kernel kiedy rysuje obrazek\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # potrzebne dla deterministycznego dziaÅ‚ania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device used is {device}\")\n",
    "\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "COMMITTEE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders_single_model(batch_size):\n",
    "    train_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transforms.ToTensor(), train=True)\n",
    "    test_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transforms.ToTensor(), train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_loaders_committee(batch_size, committee_size):\n",
    "    train_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transforms.ToTensor(), train=True)\n",
    "    test_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transforms.ToTensor(), train=False)\n",
    "\n",
    "    train_loaders = [DataLoader(train_data, batch_size=batch_size, sampler=RandomSampler(train_data, True, len(train_data))) for _ in range(committee_size)]\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_loaders, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single model\n",
    "train_loader, test_loader = get_loaders_single_model(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for committee\n",
    "train_loaders, test_loader = get_loaders_committee(BATCH_SIZE, COMMITTEE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(img, axs):\n",
    "    img_np = img.numpy()\n",
    "    img_denormalized = (img_np*255).astype(\"uint8\").transpose(1, 2, 0) \n",
    "    return axs.imshow(img_denormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5, constrained_layout=True)\n",
    "axs = np.reshape(axs, -1)\n",
    "for x in range(15):\n",
    "    img, label = train_data[x]\n",
    "    axs[x].title.set_text(classes[label])\n",
    "    print_img(img, axs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, cast, Tuple, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from ignite import distributed as idist\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics import EpochMetric\n",
    "\n",
    "\n",
    "def roc_auc_compute_fn(y_preds: torch.Tensor, y_targets: torch.Tensor) -> float:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    y_true = y_targets.cpu().numpy()\n",
    "    y_pred = y_preds.cpu().numpy()\n",
    "    return roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "\n",
    "\n",
    "def roc_auc_curve_compute_fn(y_preds: torch.Tensor, y_targets: torch.Tensor) -> Tuple[Any, Any, Any]:\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    y_true = y_targets.cpu().numpy()\n",
    "    y_pred = y_preds.cpu().numpy()\n",
    "    return roc_curve(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "class AUC(EpochMetric):\n",
    "    \"\"\"Computes Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    accumulating predictions and the ground-truth during an epoch and applying\n",
    "    `sklearn.metrics.roc_auc_score <https://scikit-learn.org/stable/modules/generated/\n",
    "    sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score>`_ .\n",
    "\n",
    "    Args:\n",
    "        output_transform: a callable that is used to transform the\n",
    "            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n",
    "            you want to compute the metric with respect to one of the outputs.\n",
    "        check_compute_fn: Default False. If True, `roc_curve\n",
    "            <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#\n",
    "            sklearn.metrics.roc_auc_score>`_ is run on the first batch of data to ensure there are\n",
    "            no issues. User will be warned in case there are any issues computing the function.\n",
    "        device: optional device specification for internal storage.\n",
    "\n",
    "    Note:\n",
    "\n",
    "        ROC_AUC expects y to be comprised of 0's and 1's. y_pred must either be probability estimates or confidence\n",
    "        values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            def sigmoid_output_transform(output):\n",
    "                y_pred, y = output\n",
    "                y_pred = torch.sigmoid(y_pred)\n",
    "                return y_pred, y\n",
    "            avg_precision = ROC_AUC(sigmoid_output_transform)\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        .. include:: defaults.rst\n",
    "            :start-after: :orphan:\n",
    "\n",
    "        .. testcode::\n",
    "\n",
    "            roc_auc = ROC_AUC()\n",
    "            #The ``output_transform`` arg of the metric can be used to perform a sigmoid on the ``y_pred``.\n",
    "            roc_auc.attach(default_evaluator, 'roc_auc')\n",
    "            y_pred = torch.tensor([[0.0474], [0.5987], [0.7109], [0.9997]])\n",
    "            y_true = torch.tensor([[0], [0], [1], [0]])\n",
    "            state = default_evaluator.run([[y_pred, y_true]])\n",
    "            print(state.metrics['roc_auc'])\n",
    "\n",
    "        .. testoutput::\n",
    "\n",
    "            0.6666...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_transform: Callable = lambda x: x,\n",
    "        check_compute_fn: bool = False,\n",
    "        device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
    "    ):\n",
    "\n",
    "        try:\n",
    "            from sklearn.metrics import roc_auc_score  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ModuleNotFoundError(\"This contrib module requires scikit-learn to be installed.\")\n",
    "\n",
    "        super(AUC, self).__init__(\n",
    "            roc_auc_compute_fn, output_transform=output_transform, check_compute_fn=check_compute_fn, device=device\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RocCurve(EpochMetric):\n",
    "    \"\"\"Compute Receiver operating characteristic (ROC) for binary classification task\n",
    "    by accumulating predictions and the ground-truth during an epoch and applying\n",
    "    `sklearn.metrics.roc_curve <https://scikit-learn.org/stable/modules/generated/\n",
    "    sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve>`_ .\n",
    "\n",
    "    Args:\n",
    "        output_transform: a callable that is used to transform the\n",
    "            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n",
    "            you want to compute the metric with respect to one of the outputs.\n",
    "        check_compute_fn: Default False. If True, `sklearn.metrics.roc_curve\n",
    "            <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#\n",
    "            sklearn.metrics.roc_curve>`_ is run on the first batch of data to ensure there are\n",
    "            no issues. User will be warned in case there are any issues computing the function.\n",
    "        device: optional device specification for internal storage.\n",
    "\n",
    "    Note:\n",
    "        RocCurve expects y to be comprised of 0's and 1's. y_pred must either be probability estimates or confidence\n",
    "        values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            def sigmoid_output_transform(output):\n",
    "                y_pred, y = output\n",
    "                y_pred = torch.sigmoid(y_pred)\n",
    "                return y_pred, y\n",
    "            avg_precision = RocCurve(sigmoid_output_transform)\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        .. include:: defaults.rst\n",
    "            :start-after: :orphan:\n",
    "\n",
    "        .. testcode::\n",
    "\n",
    "            roc_auc = RocCurve()\n",
    "            #The ``output_transform`` arg of the metric can be used to perform a sigmoid on the ``y_pred``.\n",
    "            roc_auc.attach(default_evaluator, 'roc_auc')\n",
    "            y_pred = torch.tensor([0.0474, 0.5987, 0.7109, 0.9997])\n",
    "            y_true = torch.tensor([0, 0, 1, 0])\n",
    "            state = default_evaluator.run([[y_pred, y_true]])\n",
    "            print(\"FPR\", [round(i, 3) for i in state.metrics['roc_auc'][0].tolist()])\n",
    "            print(\"TPR\", [round(i, 3) for i in state.metrics['roc_auc'][1].tolist()])\n",
    "            print(\"Thresholds\", [round(i, 3) for i in state.metrics['roc_auc'][2].tolist()])\n",
    "\n",
    "        .. testoutput::\n",
    "\n",
    "            FPR [0.0, 0.333, 0.333, 1.0]\n",
    "            TPR [0.0, 0.0, 1.0, 1.0]\n",
    "            Thresholds [2.0, 1.0, 0.711, 0.047]\n",
    "\n",
    "    ..  versionchanged:: 0.4.11\n",
    "        added `device` argument\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_transform: Callable = lambda x: x,\n",
    "        check_compute_fn: bool = False,\n",
    "        device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
    "    ) -> None:\n",
    "\n",
    "        try:\n",
    "            from sklearn.metrics import roc_curve  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ModuleNotFoundError(\"This contrib module requires scikit-learn to be installed.\")\n",
    "\n",
    "        super(RocCurve, self).__init__(\n",
    "            roc_auc_curve_compute_fn,  # type: ignore[arg-type]\n",
    "            output_transform=output_transform,\n",
    "            check_compute_fn=check_compute_fn,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "\n",
    "    def compute(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:  # type: ignore[override]\n",
    "        if len(self._predictions) < 1 or len(self._targets) < 1:\n",
    "            raise NotComputableError(\"RocCurve must have at least one example before it can be computed.\")\n",
    "\n",
    "        _prediction_tensor = torch.cat(self._predictions, dim=0)\n",
    "        _target_tensor = torch.cat(self._targets, dim=0)\n",
    "\n",
    "        ws = idist.get_world_size()\n",
    "        if ws > 1:\n",
    "            # All gather across all processes\n",
    "            _prediction_tensor = cast(torch.Tensor, idist.all_gather(_prediction_tensor))\n",
    "            _target_tensor = cast(torch.Tensor, idist.all_gather(_target_tensor))\n",
    "\n",
    "        if idist.get_rank() == 0:\n",
    "            # Run compute_fn on zero rank only\n",
    "            fpr, tpr, thresholds = cast(Tuple, self.compute_fn(_prediction_tensor, _target_tensor))\n",
    "            fpr = torch.tensor(fpr, device=_prediction_tensor.device)\n",
    "            tpr = torch.tensor(tpr, device=_prediction_tensor.device)\n",
    "            thresholds = torch.tensor(thresholds, device=_prediction_tensor.device)\n",
    "        else:\n",
    "            fpr, tpr, thresholds = None, None, None\n",
    "\n",
    "        if ws > 1:\n",
    "            # broadcast result to all processes\n",
    "            fpr = idist.broadcast(fpr, src=0, safe_mode=True)\n",
    "            tpr = idist.broadcast(tpr, src=0, safe_mode=True)\n",
    "            thresholds = idist.broadcast(thresholds, src=0, safe_mode=True)\n",
    "\n",
    "        return fpr, tpr, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Committee(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "\n",
    "    def forward(self, x):\n",
    "        predictions = torch.stack([model.forward(x).argmax(1) for model in self.models])\n",
    "        predictions = torch.stack([predictions[:, i].bincount(minlength=10) for i in range(x.shape[0])]).float()\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, draw=True, save=False, savefile=\"\"):\n",
    "    plt.figure()\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(classes)\n",
    "    ax.yaxis.set_ticklabels(classes)\n",
    "\n",
    "    if draw:\n",
    "        plt.show()\n",
    "    if save and savefile and savefile.strip():\n",
    "        plt.savefig(f\"plots/{savefile}.png\")\n",
    "\n",
    "def softmax_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = torch.softmax(y_pred, 1)\n",
    "    return y_pred, y\n",
    "\n",
    "def to_cpy_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    return y_pred.to(\"cpu\"), y.to(\"cpu\")\n",
    "\n",
    "\n",
    "def run_model(model, train_loader, test_loader, device=device, draw=True, save=False, savefile=\"\"):\n",
    "    model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    trainer = create_supervised_trainer(model, optimizer, loss_fn, device)\n",
    "\n",
    "    val_metrics = {\n",
    "        \"accuracy\": Accuracy(device=device),\n",
    "        \"loss\": Loss(loss_fn, device=device),\n",
    "        \"auc\": AUC(softmax_output_transform, device=device),\n",
    "        \"confusion_matrix\": ConfusionMatrix(10, output_transform=to_cpy_output_transform)\n",
    "    }\n",
    "\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "    val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        train_evaluator.run(train_loader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}, AUC: {metrics['auc']:.2f}\")\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(trainer):\n",
    "        val_evaluator.run(test_loader)\n",
    "        metrics = val_evaluator.state.metrics\n",
    "        # print(metrics[\"confusion_matrix\"])\n",
    "        print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}, AUC: {metrics['auc']:.2f}\")\n",
    "\n",
    "    def score_function(engine):\n",
    "        metrics = engine.state.metrics\n",
    "        return metrics[\"accuracy\"]\n",
    "    \n",
    "\n",
    "    val_evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(3, score_function, trainer))\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=100)\n",
    "    plot_confusion_matrix(val_evaluator.state.metrics[\"confusion_matrix\"], draw, save, savefile)\n",
    "\n",
    "\n",
    "def run_models(models, train_loaders, test_loader, device=device, draw=True, save=False, savefile=\"\"):\n",
    "    assert len(models) == len(train_loaders), \"Number of models and number of train_loaders should be equal\"\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Training model #{i + 1}...\")\n",
    "\n",
    "        model.to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        trainer = create_supervised_trainer(model, optimizer, loss_fn, device)\n",
    "\n",
    "        val_metrics = {\n",
    "            \"accuracy\": Accuracy(device=device),\n",
    "            \"loss\": Loss(loss_fn, device=device),\n",
    "            \"auc\": AUC(softmax_output_transform, device=device)\n",
    "        }\n",
    "\n",
    "        train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "        val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "\n",
    "        @trainer.on(Events.EPOCH_COMPLETED)\n",
    "        def log_training_results(trainer):\n",
    "            train_evaluator.run(train_loaders[i])\n",
    "            metrics = train_evaluator.state.metrics\n",
    "            print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}, AUC: {metrics['auc']:.2f}\")\n",
    "\n",
    "        @trainer.on(Events.EPOCH_COMPLETED)\n",
    "        def log_validation_results(trainer):\n",
    "            val_evaluator.run(test_loader)\n",
    "            metrics = val_evaluator.state.metrics\n",
    "            print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}, AUC: {metrics['auc']:.2f}\")\n",
    "\n",
    "        def score_function(engine):\n",
    "            metrics = engine.state.metrics\n",
    "            return metrics[\"accuracy\"]\n",
    "\n",
    "\n",
    "        val_evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(3, score_function, trainer))\n",
    "        trainer.run(train_loaders[i], max_epochs=100)\n",
    "\n",
    "\n",
    "    committee = Committee(models)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    val_metrics = {\n",
    "        \"accuracy\": Accuracy(device=device),\n",
    "        \"loss\": Loss(loss_fn, device=device),\n",
    "        \"auc\": AUC(softmax_output_transform, device=device),\n",
    "        \"confusion_matrix\": ConfusionMatrix(10, device=device)\n",
    "    }\n",
    "    evaluator = create_supervised_evaluator(committee, metrics=val_metrics, device=device)\n",
    "\n",
    "    @evaluator.on(Events.COMPLETED)\n",
    "    def log_committee_results(evaluator):\n",
    "        metrics = evaluator.state.metrics\n",
    "        print(f\"Validation Results - Committee Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}, AUC: {metrics['auc']:.2f}\")\n",
    "\n",
    "    evaluator.run(test_loader)\n",
    "    plot_confusion_matrix(evaluator.state.metrics[\"confusion_matrix\"], draw, save, savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, conv_channels, kernel_sizes, fc_sizes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(len(kernel_sizes)):\n",
    "            self.convs.append(nn.Conv2d(conv_channels[i], conv_channels[i + 1], kernel_sizes[i]))\n",
    "\n",
    "        self.fcs = nn.ModuleList()\n",
    "        for i in range(len(fc_sizes) - 1):\n",
    "            self.fcs.append(nn.Linear(fc_sizes[i], fc_sizes[i + 1]))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x))\n",
    "            \n",
    "        x = torch.flatten(x, 1)\n",
    "        for fc in self.fcs[:-1]:\n",
    "            x = F.relu(fc(x))\n",
    "\n",
    "        x = self.fcs[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PoolingNet(nn.Module):\n",
    "    def __init__(self, conv_channels, kernel_sizes, pools, fc_sizes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(len(kernel_sizes)):\n",
    "            if pools[i]:\n",
    "                self.convs.append(nn.Sequential([\n",
    "                    nn.Conv2d(conv_channels[i], conv_channels[i + 1], kernel_sizes[i]),\n",
    "                    nn.MaxPool2d(2, 2)\n",
    "                ]))\n",
    "            else:\n",
    "                self.convs.append(nn.Conv2d(conv_channels[i], conv_channels[i + 1], kernel_sizes[i]))\n",
    "\n",
    "        self.fcs = nn.ModuleList()\n",
    "        for i in range(len(fc_sizes) - 1):\n",
    "            self.fcs.append(nn.Linear(fc_sizes[i], fc_sizes[i + 1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        for fc in self.fcs[:-1]:\n",
    "            x = F.relu(fc(x))\n",
    "\n",
    "        x = self.fcs[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ResidualNet._conv_block(3, 64, True)\n",
    "        self.conv2 = ResidualNet._conv_block(64, 128, True)\n",
    "        self.conv3 = ResidualNet._conv_block(128, 128)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(self.conv3(x)) + x\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def _conv_block(in_channels, out_channels, pool=False):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "                nn.BatchNorm2d(out_channels), \n",
    "                nn.ReLU(inplace=True)]\n",
    "        if pool:\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet([3, 6, 16, 32, 64], [5, 5, 5, 5], [64 * 16 * 16, 120, 84, 32, 10])\n",
    "run_model(model, train_loader, test_loader, draw=False, save=True, savefile=\"SimpleNet_kernel_5_Single\")\n",
    "\n",
    "model = SimpleNet([3, 6, 16, 32, 64], [3, 3, 3, 3], [64 * 16 * 16, 120, 84, 32, 10])\n",
    "run_model(model, train_loader, test_loader, draw=False, save=True, savefile=\"SimpleNet_kernel_3_Single\")\n",
    "\n",
    "model = PoolingNet([3, 6, 16, 32], [3, 3, 3, 3], [True, True, False], [32 * 4 * 4, 120, 84, 64, 32, 10])\n",
    "run_model(model, train_loader, test_loader, draw=False, save=True, savefile=\"PoolingNet_Single\")\n",
    "\n",
    "model = ResidualNet()\n",
    "run_model(model, train_loader, test_loader, draw=False, save=True, savefile=\"ResidualNet_Single\")\n",
    "\n",
    "\n",
    "train_loaders, test_loader = get_loaders_committee(BATCH_SIZE, COMMITTEE_SIZE)\n",
    "\n",
    "models = [SimpleNet([3, 6, 16, 32, 64], [5, 5, 5, 5], [64 * 16 * 16, 120, 84, 32, 10]) for _ in range(COMMITTEE_SIZE)]\n",
    "run_models(models, train_loaders, test_loader, draw=False, save=True, savefile=\"SimpleNet_kernel_5_Committee\")\n",
    "\n",
    "models = [SimpleNet([3, 6, 16, 32, 64], [3, 3, 3, 3], [64 * 16 * 16, 120, 84, 32, 10]) for _ in range(COMMITTEE_SIZE)]\n",
    "run_models(models, train_loaders, test_loader, draw=False, save=True, savefile=\"SimpleNet_kernel_3_Committee\")\n",
    "\n",
    "models = [PoolingNet([3, 6, 16, 32], [3, 3, 3, 3], [True, True, False], [32 * 4 * 4, 120, 84, 64, 32, 10]) for _ in range(COMMITTEE_SIZE)]\n",
    "run_models(models, train_loaders, test_loader, draw=False, save=True, savefile=\"PoolingNet_Committee\")\n",
    "\n",
    "model = [ResidualNet() for _ in range(COMMITTEE_SIZE)]\n",
    "run_model(model, train_loader, test_loader, draw=False, save=True, savefile=\"ResidualNet_Single\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 3 - Validation Results - Epoch[11] Avg accuracy: 55.59%, Avg loss: 1.34\n",
    "2 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.85%, Avg loss: 1.34\n",
    "\n",
    "3 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.77%, Avg loss: 1.23\n",
    "3 + 4 - Validation Results - Epoch[12] Avg accuracy: 61.44%, Avg loss: 1.42\n",
    "3 + 5 - Validation Results - Epoch[15] Avg accuracy: 57.74%, Avg loss: 1.47\n",
    "\n",
    "4 + 3 - Validation Results - Epoch[11] Avg accuracy: 59.61%, Avg loss: 1.36\n",
    "4 + 4 - Validation Results - Epoch[15] Avg accuracy: 61.82%, Avg loss: 1.52\n",
    "4 + 5 - Validation Results - Epoch[19] Avg accuracy: 60.91%, Avg loss: 1.24\n",
    "\n",
    "5 + 3 - Validation Results - Epoch[18] Avg accuracy: 60.97%, Avg loss: 1.17\n",
    "5 + 4 - Validation Results - Epoch[14] Avg accuracy: 60.22%, Avg loss: 1.24\n",
    "5 + 5 - Validation Results - Epoch[23] Avg accuracy: 61.34%, Avg loss: 1.33\n",
    "5 + 6 - Validation Results - Epoch[20] Avg accuracy: 59.16%, Avg loss: 1.23\n",
    "\n",
    "6 + 3 - Validation Results - Epoch[17] Avg accuracy: 60.48%, Avg loss: 1.22\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pooling\n",
    "2 + 2 - Validation Results - Epoch[16] Avg accuracy: 61.48%, Avg loss: 1.09\n",
    "2 + 3 - Validation Results - Epoch[19] Avg accuracy: 61.46%, Avg loss: 1.11\n",
    "2 + 4 - Validation Results - Epoch[17] Avg accuracy: 61.60%, Avg loss: 1.10\n",
    "2 + 5 - Validation Results - Epoch[17] Avg accuracy: 58.76%, Avg loss: 1.23\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[25] Avg accuracy: 63.66%, Avg loss: 1.10  # 3x3 kernel\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[65] Avg accuracy: 59.91%, Avg loss: 1.17  # sigmoid\n",
    "2 + 3 - Validation Results - Epoch[31] Avg accuracy: 56.99%, Avg loss: 1.21  # sigmoid\n",
    "2 + 4 - Validation Results - Epoch[40] Avg accuracy: 59.25%, Avg loss: 1.17  # sigmoid\n",
    "2 + 2 - Validation Results - Epoch[22] Avg accuracy: 52.06%, Avg loss: 1.33  # 3x3 kernel sigmoid\n",
    "\n",
    "3 + 4 - Validation Results - Epoch[15] Avg accuracy: 65.09%, Avg loss: 1.09  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[20] Avg accuracy: 65.20%, Avg loss: 1.11  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[22] Avg accuracy: 64.24%, Avg loss: 1.11  # 3v3 kernel, no pooling on last conv\n",
    "\n",
    "3 + 5 - Validation Results - Epoch[14] Avg accuracy: 71.76%, Avg loss: 0.91  # 3v3 kernel, no pooling on last conv, 3 -> 64 -> 128 -> 128 channels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Results - Epoch[11] Avg accuracy: 76.68%, Avg loss: 0.89  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c + 5 fc\n",
    "Validation Results - Epoch[14] Avg accuracy: 77.51%, Avg loss: 0.99  # j.w. + 4 fc, last with relu\n",
    "Validation Results - Epoch[11] Avg accuracy: 77.01%, Avg loss: 0.81  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c -- 3 conv + 5 fc, res on last conv\n",
    "Validation Results - Epoch[16] Avg accuracy: 77.53%, Avg loss: 0.96  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c -- 2 conv + res + 4 fc, res on last conv which is double (actually as in article)  -- left in model in commit\n",
    "Validation Results - Epoch[13] Avg accuracy: 67.98%, Avg loss: 1.30  # same as above but two res modules\n",
    "Validation Results - Epoch[12] Avg accuracy: 70.42%, Avg loss: 1.37  # 2 conv + res + 1 conv + 4 fc\n",
    "Validation Results - Epoch[10] Avg accuracy: 68.59%, Avg loss: 1.47  # 2 conv + res + 2 conv + res + 4 fc\n",
    "Validation Results - Epoch[11] Avg accuracy: 69.94%, Avg loss: 1.33  # 2 conv + res + 2 conv + res + 5 fc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Results - Committee Avg accuracy: 81.64%, Avg loss: 0.65, AUC: 0.97  # best residual + committee"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
