{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, Metric\n",
    "from ignite.handlers import EarlyStopping\n",
    "from ignite.contrib.metrics import ROC_AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bez tego wysadza kernel kiedy rysuje obrazek\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a5e1dfb90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {\n",
    "    0: \"plane\",\n",
    "    1: \"car\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "batch_size = 64\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # this includes scaling to [0, 1]\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=True)\n",
    "test_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(test_data)\n",
    "print(train_data[0][0].size())\n",
    "print(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(img, axs):\n",
    "    img_np = img.numpy()\n",
    "    img_denormalized = (img_np*255).astype(\"uint8\").transpose(1, 2, 0) \n",
    "    return axs.imshow(img_denormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5, constrained_layout=True)\n",
    "axs = np.reshape(axs, -1)\n",
    "for x in range(15):\n",
    "    img, label = train_data[x]\n",
    "    axs[x].title.set_text(classes[label])\n",
    "    print_img(img, axs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, cast, Tuple, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from ignite import distributed as idist\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics import EpochMetric\n",
    "\n",
    "\n",
    "def roc_auc_compute_fn(y_preds: torch.Tensor, y_targets: torch.Tensor) -> float:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    y_true = y_targets.cpu().numpy()\n",
    "    y_pred = y_preds.cpu().numpy()\n",
    "    return roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "\n",
    "\n",
    "def roc_auc_curve_compute_fn(y_preds: torch.Tensor, y_targets: torch.Tensor) -> Tuple[Any, Any, Any]:\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    y_true = y_targets.cpu().numpy()\n",
    "    y_pred = y_preds.cpu().numpy()\n",
    "    return roc_curve(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "class AUC(EpochMetric):\n",
    "    \"\"\"Computes Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "    accumulating predictions and the ground-truth during an epoch and applying\n",
    "    `sklearn.metrics.roc_auc_score <https://scikit-learn.org/stable/modules/generated/\n",
    "    sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score>`_ .\n",
    "\n",
    "    Args:\n",
    "        output_transform: a callable that is used to transform the\n",
    "            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n",
    "            you want to compute the metric with respect to one of the outputs.\n",
    "        check_compute_fn: Default False. If True, `roc_curve\n",
    "            <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#\n",
    "            sklearn.metrics.roc_auc_score>`_ is run on the first batch of data to ensure there are\n",
    "            no issues. User will be warned in case there are any issues computing the function.\n",
    "        device: optional device specification for internal storage.\n",
    "\n",
    "    Note:\n",
    "\n",
    "        ROC_AUC expects y to be comprised of 0's and 1's. y_pred must either be probability estimates or confidence\n",
    "        values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            def sigmoid_output_transform(output):\n",
    "                y_pred, y = output\n",
    "                y_pred = torch.sigmoid(y_pred)\n",
    "                return y_pred, y\n",
    "            avg_precision = ROC_AUC(sigmoid_output_transform)\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        .. include:: defaults.rst\n",
    "            :start-after: :orphan:\n",
    "\n",
    "        .. testcode::\n",
    "\n",
    "            roc_auc = ROC_AUC()\n",
    "            #The ``output_transform`` arg of the metric can be used to perform a sigmoid on the ``y_pred``.\n",
    "            roc_auc.attach(default_evaluator, 'roc_auc')\n",
    "            y_pred = torch.tensor([[0.0474], [0.5987], [0.7109], [0.9997]])\n",
    "            y_true = torch.tensor([[0], [0], [1], [0]])\n",
    "            state = default_evaluator.run([[y_pred, y_true]])\n",
    "            print(state.metrics['roc_auc'])\n",
    "\n",
    "        .. testoutput::\n",
    "\n",
    "            0.6666...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_transform: Callable = lambda x: x,\n",
    "        check_compute_fn: bool = False,\n",
    "        device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
    "    ):\n",
    "\n",
    "        try:\n",
    "            from sklearn.metrics import roc_auc_score  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ModuleNotFoundError(\"This contrib module requires scikit-learn to be installed.\")\n",
    "\n",
    "        super(AUC, self).__init__(\n",
    "            roc_auc_compute_fn, output_transform=output_transform, check_compute_fn=check_compute_fn, device=device\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RocCurve(EpochMetric):\n",
    "    \"\"\"Compute Receiver operating characteristic (ROC) for binary classification task\n",
    "    by accumulating predictions and the ground-truth during an epoch and applying\n",
    "    `sklearn.metrics.roc_curve <https://scikit-learn.org/stable/modules/generated/\n",
    "    sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve>`_ .\n",
    "\n",
    "    Args:\n",
    "        output_transform: a callable that is used to transform the\n",
    "            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n",
    "            you want to compute the metric with respect to one of the outputs.\n",
    "        check_compute_fn: Default False. If True, `sklearn.metrics.roc_curve\n",
    "            <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#\n",
    "            sklearn.metrics.roc_curve>`_ is run on the first batch of data to ensure there are\n",
    "            no issues. User will be warned in case there are any issues computing the function.\n",
    "        device: optional device specification for internal storage.\n",
    "\n",
    "    Note:\n",
    "        RocCurve expects y to be comprised of 0's and 1's. y_pred must either be probability estimates or confidence\n",
    "        values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            def sigmoid_output_transform(output):\n",
    "                y_pred, y = output\n",
    "                y_pred = torch.sigmoid(y_pred)\n",
    "                return y_pred, y\n",
    "            avg_precision = RocCurve(sigmoid_output_transform)\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        .. include:: defaults.rst\n",
    "            :start-after: :orphan:\n",
    "\n",
    "        .. testcode::\n",
    "\n",
    "            roc_auc = RocCurve()\n",
    "            #The ``output_transform`` arg of the metric can be used to perform a sigmoid on the ``y_pred``.\n",
    "            roc_auc.attach(default_evaluator, 'roc_auc')\n",
    "            y_pred = torch.tensor([0.0474, 0.5987, 0.7109, 0.9997])\n",
    "            y_true = torch.tensor([0, 0, 1, 0])\n",
    "            state = default_evaluator.run([[y_pred, y_true]])\n",
    "            print(\"FPR\", [round(i, 3) for i in state.metrics['roc_auc'][0].tolist()])\n",
    "            print(\"TPR\", [round(i, 3) for i in state.metrics['roc_auc'][1].tolist()])\n",
    "            print(\"Thresholds\", [round(i, 3) for i in state.metrics['roc_auc'][2].tolist()])\n",
    "\n",
    "        .. testoutput::\n",
    "\n",
    "            FPR [0.0, 0.333, 0.333, 1.0]\n",
    "            TPR [0.0, 0.0, 1.0, 1.0]\n",
    "            Thresholds [2.0, 1.0, 0.711, 0.047]\n",
    "\n",
    "    ..  versionchanged:: 0.4.11\n",
    "        added `device` argument\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_transform: Callable = lambda x: x,\n",
    "        check_compute_fn: bool = False,\n",
    "        device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
    "    ) -> None:\n",
    "\n",
    "        try:\n",
    "            from sklearn.metrics import roc_curve  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ModuleNotFoundError(\"This contrib module requires scikit-learn to be installed.\")\n",
    "\n",
    "        super(RocCurve, self).__init__(\n",
    "            roc_auc_curve_compute_fn,  # type: ignore[arg-type]\n",
    "            output_transform=output_transform,\n",
    "            check_compute_fn=check_compute_fn,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "\n",
    "    def compute(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:  # type: ignore[override]\n",
    "        if len(self._predictions) < 1 or len(self._targets) < 1:\n",
    "            raise NotComputableError(\"RocCurve must have at least one example before it can be computed.\")\n",
    "\n",
    "        _prediction_tensor = torch.cat(self._predictions, dim=0)\n",
    "        _target_tensor = torch.cat(self._targets, dim=0)\n",
    "\n",
    "        ws = idist.get_world_size()\n",
    "        if ws > 1:\n",
    "            # All gather across all processes\n",
    "            _prediction_tensor = cast(torch.Tensor, idist.all_gather(_prediction_tensor))\n",
    "            _target_tensor = cast(torch.Tensor, idist.all_gather(_target_tensor))\n",
    "\n",
    "        if idist.get_rank() == 0:\n",
    "            # Run compute_fn on zero rank only\n",
    "            fpr, tpr, thresholds = cast(Tuple, self.compute_fn(_prediction_tensor, _target_tensor))\n",
    "            fpr = torch.tensor(fpr, device=_prediction_tensor.device)\n",
    "            tpr = torch.tensor(tpr, device=_prediction_tensor.device)\n",
    "            thresholds = torch.tensor(thresholds, device=_prediction_tensor.device)\n",
    "        else:\n",
    "            fpr, tpr, thresholds = None, None, None\n",
    "\n",
    "        if ws > 1:\n",
    "            # broadcast result to all processes\n",
    "            fpr = idist.broadcast(fpr, src=0, safe_mode=True)\n",
    "            tpr = idist.broadcast(tpr, src=0, safe_mode=True)\n",
    "            thresholds = idist.broadcast(thresholds, src=0, safe_mode=True)\n",
    "\n",
    "        return fpr, tpr, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = torch.softmax(y_pred, 1)\n",
    "    return y_pred, y\n",
    "\n",
    "\n",
    "def run_model(model):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    trainer = create_supervised_trainer(model, optimizer, loss_fn, device)\n",
    "\n",
    "    val_metrics = {\n",
    "        \"accuracy\": Accuracy(),\n",
    "        \"loss\": Loss(loss_fn),\n",
    "        \"auc\": AUC(softmax_output_transform)\n",
    "    }\n",
    "\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "    val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        train_evaluator.run(train_loader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}, AUC: {metrics['auc']:.2f}\")\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(trainer):\n",
    "        val_evaluator.run(test_loader)\n",
    "        metrics = val_evaluator.state.metrics\n",
    "        print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}, AUC: {metrics['auc']:.2f}\")\n",
    "\n",
    "    def score_function(engine):\n",
    "        metrics = engine.state.metrics\n",
    "        return metrics[\"accuracy\"]\n",
    "    \n",
    "    val_evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(3, score_function, trainer))\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch[1] Avg accuracy: 56.68%, Avg loss: 1.21, AUC: 0.92\n",
      "Validation Results - Epoch[1] Avg accuracy: 55.95%, Avg loss: 1.24, AUC: 0.92\n",
      "Training Results - Epoch[2] Avg accuracy: 63.02%, Avg loss: 1.03, AUC: 0.95\n",
      "Validation Results - Epoch[2] Avg accuracy: 61.19%, Avg loss: 1.10, AUC: 0.94\n",
      "Training Results - Epoch[3] Avg accuracy: 72.61%, Avg loss: 0.79, AUC: 0.97\n",
      "Validation Results - Epoch[3] Avg accuracy: 69.62%, Avg loss: 0.88, AUC: 0.96\n",
      "Training Results - Epoch[4] Avg accuracy: 72.91%, Avg loss: 0.78, AUC: 0.97\n",
      "Validation Results - Epoch[4] Avg accuracy: 68.32%, Avg loss: 0.92, AUC: 0.96\n",
      "Training Results - Epoch[5] Avg accuracy: 71.16%, Avg loss: 0.89, AUC: 0.96\n",
      "Validation Results - Epoch[5] Avg accuracy: 66.56%, Avg loss: 1.05, AUC: 0.95\n",
      "Training Results - Epoch[6] Avg accuracy: 83.39%, Avg loss: 0.48, AUC: 0.99\n",
      "Validation Results - Epoch[6] Avg accuracy: 76.56%, Avg loss: 0.70, AUC: 0.97\n",
      "Training Results - Epoch[7] Avg accuracy: 85.57%, Avg loss: 0.42, AUC: 0.99\n",
      "Validation Results - Epoch[7] Avg accuracy: 76.88%, Avg loss: 0.69, AUC: 0.97\n",
      "Training Results - Epoch[8] Avg accuracy: 87.70%, Avg loss: 0.36, AUC: 0.99\n",
      "Validation Results - Epoch[8] Avg accuracy: 77.46%, Avg loss: 0.72, AUC: 0.97\n",
      "Training Results - Epoch[9] Avg accuracy: 91.14%, Avg loss: 0.26, AUC: 1.00\n",
      "Validation Results - Epoch[9] Avg accuracy: 78.94%, Avg loss: 0.67, AUC: 0.98\n",
      "Training Results - Epoch[10] Avg accuracy: 91.31%, Avg loss: 0.25, AUC: 1.00\n",
      "Validation Results - Epoch[10] Avg accuracy: 78.22%, Avg loss: 0.72, AUC: 0.98\n",
      "Training Results - Epoch[11] Avg accuracy: 88.44%, Avg loss: 0.33, AUC: 1.00\n",
      "Validation Results - Epoch[11] Avg accuracy: 75.69%, Avg loss: 0.86, AUC: 0.97\n",
      "Training Results - Epoch[12] Avg accuracy: 90.43%, Avg loss: 0.28, AUC: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 19:24:48,328 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch[12] Avg accuracy: 76.68%, Avg loss: 0.88, AUC: 0.97\n"
     ]
    }
   ],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_block(3, 64, True)\n",
    "        self.conv2 = conv_block(64, 128, True)\n",
    "        self.conv3 = conv_block(128, 128)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(self.conv3(x)) + x\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "model = Net().to(device)\n",
    "run_model(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 3 - Validation Results - Epoch[11] Avg accuracy: 55.59%, Avg loss: 1.34\n",
    "2 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.85%, Avg loss: 1.34\n",
    "\n",
    "3 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.77%, Avg loss: 1.23\n",
    "3 + 4 - Validation Results - Epoch[12] Avg accuracy: 61.44%, Avg loss: 1.42\n",
    "3 + 5 - Validation Results - Epoch[15] Avg accuracy: 57.74%, Avg loss: 1.47\n",
    "\n",
    "4 + 3 - Validation Results - Epoch[11] Avg accuracy: 59.61%, Avg loss: 1.36\n",
    "4 + 4 - Validation Results - Epoch[15] Avg accuracy: 61.82%, Avg loss: 1.52\n",
    "4 + 5 - Validation Results - Epoch[19] Avg accuracy: 60.91%, Avg loss: 1.24\n",
    "\n",
    "5 + 3 - Validation Results - Epoch[18] Avg accuracy: 60.97%, Avg loss: 1.17\n",
    "5 + 4 - Validation Results - Epoch[14] Avg accuracy: 60.22%, Avg loss: 1.24\n",
    "5 + 5 - Validation Results - Epoch[23] Avg accuracy: 61.34%, Avg loss: 1.33\n",
    "5 + 6 - Validation Results - Epoch[20] Avg accuracy: 59.16%, Avg loss: 1.23\n",
    "\n",
    "6 + 3 - Validation Results - Epoch[17] Avg accuracy: 60.48%, Avg loss: 1.22\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pooling\n",
    "2 + 2 - Validation Results - Epoch[16] Avg accuracy: 61.48%, Avg loss: 1.09\n",
    "2 + 3 - Validation Results - Epoch[19] Avg accuracy: 61.46%, Avg loss: 1.11\n",
    "2 + 4 - Validation Results - Epoch[17] Avg accuracy: 61.60%, Avg loss: 1.10\n",
    "2 + 5 - Validation Results - Epoch[17] Avg accuracy: 58.76%, Avg loss: 1.23\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[25] Avg accuracy: 63.66%, Avg loss: 1.10  # 3x3 kernel\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[65] Avg accuracy: 59.91%, Avg loss: 1.17  # sigmoid\n",
    "2 + 3 - Validation Results - Epoch[31] Avg accuracy: 56.99%, Avg loss: 1.21  # sigmoid\n",
    "2 + 4 - Validation Results - Epoch[40] Avg accuracy: 59.25%, Avg loss: 1.17  # sigmoid\n",
    "2 + 2 - Validation Results - Epoch[22] Avg accuracy: 52.06%, Avg loss: 1.33  # 3x3 kernel sigmoid\n",
    "\n",
    "3 + 4 - Validation Results - Epoch[15] Avg accuracy: 65.09%, Avg loss: 1.09  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[20] Avg accuracy: 65.20%, Avg loss: 1.11  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[22] Avg accuracy: 64.24%, Avg loss: 1.11  # 3v3 kernel, no pooling on last conv\n",
    "\n",
    "3 + 5 - Validation Results - Epoch[14] Avg accuracy: 71.76%, Avg loss: 0.91  # 3v3 kernel, no pooling on last conv, 3 -> 64 -> 128 -> 128 channels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Results - Epoch[11] Avg accuracy: 76.68%, Avg loss: 0.89  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c + 5 fc\n",
    "Validation Results - Epoch[14] Avg accuracy: 77.51%, Avg loss: 0.99  # j.w. + 4 fc, last with relu\n",
    "Validation Results - Epoch[11] Avg accuracy: 77.01%, Avg loss: 0.81  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c -- 3 conv + 5 fc, res on last conv\n",
    "Validation Results - Epoch[16] Avg accuracy: 77.53%, Avg loss: 0.96  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c -- 2 conv + res + 4 fc, res on last conv which is double (actually as in article)  -- left in model in commit\n",
    "Validation Results - Epoch[13] Avg accuracy: 67.98%, Avg loss: 1.30  # same as above but two res modules\n",
    "Validation Results - Epoch[12] Avg accuracy: 70.42%, Avg loss: 1.37  # 2 conv + res + 1 conv + 4 fc\n",
    "Validation Results - Epoch[10] Avg accuracy: 68.59%, Avg loss: 1.47  # 2 conv + res + 2 conv + res + 4 fc\n",
    "Validation Results - Epoch[11] Avg accuracy: 69.94%, Avg loss: 1.33  # 2 conv + res + 2 conv + res + 5 fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
