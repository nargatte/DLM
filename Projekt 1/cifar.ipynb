{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bez tego wysadza kernel kiedy rysuje obrazek\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8004b63b90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {\n",
    "    0: \"plane\",\n",
    "    1: \"car\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "\n",
    "device = \"cuda\"\n",
    "batch_size = 64\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # this includes scaling to [0, 1]\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=True)\n",
    "test_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(test_data)\n",
    "print(train_data[0][0].size())\n",
    "print(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(img, axs):\n",
    "    img_np = img.numpy()\n",
    "    img_denormalized = (img_np*255).astype(\"uint8\").transpose(1, 2, 0) \n",
    "    return axs.imshow(img_denormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5, constrained_layout=True)\n",
    "axs = np.reshape(axs, -1)\n",
    "for x in range(15):\n",
    "    img, label = train_data[x]\n",
    "    axs[x].title.set_text(classes[label])\n",
    "    print_img(img, axs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    trainer = create_supervised_trainer(model, optimizer, loss_fn, device)\n",
    "\n",
    "    val_metrics = {\n",
    "        \"accuracy\": Accuracy(),\n",
    "        \"loss\": Loss(loss_fn)\n",
    "    }\n",
    "\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "    val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        train_evaluator.run(train_loader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(trainer):\n",
    "        val_evaluator.run(test_loader)\n",
    "        metrics = val_evaluator.state.metrics\n",
    "        print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "    def score_function(engine):\n",
    "        metrics = engine.state.metrics\n",
    "        return metrics[\"accuracy\"]\n",
    "    \n",
    "    val_evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(3, score_function, trainer))\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch[1] Avg accuracy: 44.37%, Avg loss: 1.50\n",
      "Validation Results - Epoch[1] Avg accuracy: 43.53%, Avg loss: 1.52\n",
      "Training Results - Epoch[2] Avg accuracy: 55.74%, Avg loss: 1.24\n",
      "Validation Results - Epoch[2] Avg accuracy: 53.38%, Avg loss: 1.30\n",
      "Training Results - Epoch[3] Avg accuracy: 60.24%, Avg loss: 1.11\n",
      "Validation Results - Epoch[3] Avg accuracy: 56.67%, Avg loss: 1.21\n",
      "Training Results - Epoch[4] Avg accuracy: 64.18%, Avg loss: 1.01\n",
      "Validation Results - Epoch[4] Avg accuracy: 59.00%, Avg loss: 1.15\n",
      "Training Results - Epoch[5] Avg accuracy: 67.63%, Avg loss: 0.92\n",
      "Validation Results - Epoch[5] Avg accuracy: 60.31%, Avg loss: 1.13\n",
      "Training Results - Epoch[6] Avg accuracy: 70.12%, Avg loss: 0.85\n",
      "Validation Results - Epoch[6] Avg accuracy: 61.41%, Avg loss: 1.14\n",
      "Training Results - Epoch[7] Avg accuracy: 74.10%, Avg loss: 0.74\n",
      "Validation Results - Epoch[7] Avg accuracy: 62.07%, Avg loss: 1.11\n",
      "Training Results - Epoch[8] Avg accuracy: 74.74%, Avg loss: 0.72\n",
      "Validation Results - Epoch[8] Avg accuracy: 61.13%, Avg loss: 1.21\n",
      "Training Results - Epoch[9] Avg accuracy: 81.07%, Avg loss: 0.54\n",
      "Validation Results - Epoch[9] Avg accuracy: 62.67%, Avg loss: 1.17\n",
      "Training Results - Epoch[10] Avg accuracy: 81.74%, Avg loss: 0.52\n",
      "Validation Results - Epoch[10] Avg accuracy: 61.94%, Avg loss: 1.24\n",
      "Training Results - Epoch[11] Avg accuracy: 86.68%, Avg loss: 0.39\n",
      "Validation Results - Epoch[11] Avg accuracy: 62.05%, Avg loss: 1.31\n",
      "Training Results - Epoch[12] Avg accuracy: 87.52%, Avg loss: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 23:08:10,734 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch[12] Avg accuracy: 61.44%, Avg loss: 1.42\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv4 = nn.Conv2d(32, 48, 5)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc1 = nn.Linear(6 * 28 * 28, 120)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "        self.fc6 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "model = Net().to(device)\n",
    "run_model(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 3 - Validation Results - Epoch[11] Avg accuracy: 55.59%, Avg loss: 1.34\n",
    "2 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.85%, Avg loss: 1.34\n",
    "\n",
    "3 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.77%, Avg loss: 1.23\n",
    "3 + 4 - Validation Results - Epoch[12] Avg accuracy: 61.44%, Avg loss: 1.42\n",
    "3 + 5 - Validation Results - Epoch[15] Avg accuracy: 57.74%, Avg loss: 1.47\n",
    "\n",
    "4 + 3 - Validation Results - Epoch[11] Avg accuracy: 59.61%, Avg loss: 1.36\n",
    "4 + 4 - Validation Results - Epoch[15] Avg accuracy: 61.82%, Avg loss: 1.52\n",
    "4 + 5 - Validation Results - Epoch[19] Avg accuracy: 60.91%, Avg loss: 1.24\n",
    "\n",
    "5 + 3 - Validation Results - Epoch[18] Avg accuracy: 60.97%, Avg loss: 1.17\n",
    "5 + 4 - Validation Results - Epoch[14] Avg accuracy: 60.22%, Avg loss: 1.24\n",
    "5 + 5 - Validation Results - Epoch[23] Avg accuracy: 61.34%, Avg loss: 1.33\n",
    "5 + 6 - Validation Results - Epoch[20] Avg accuracy: 59.16%, Avg loss: 1.23\n",
    "\n",
    "6 + 3 - Validation Results - Epoch[17] Avg accuracy: 60.48%, Avg loss: 1.22\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
