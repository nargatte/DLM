{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bez tego wysadza kernel kiedy rysuje obrazek\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a5e1dfb90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {\n",
    "    0: \"plane\",\n",
    "    1: \"car\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "batch_size = 64\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # this includes scaling to [0, 1]\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=True)\n",
    "test_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(test_data)\n",
    "print(train_data[0][0].size())\n",
    "print(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(img, axs):\n",
    "    img_np = img.numpy()\n",
    "    img_denormalized = (img_np*255).astype(\"uint8\").transpose(1, 2, 0) \n",
    "    return axs.imshow(img_denormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5, constrained_layout=True)\n",
    "axs = np.reshape(axs, -1)\n",
    "for x in range(15):\n",
    "    img, label = train_data[x]\n",
    "    axs[x].title.set_text(classes[label])\n",
    "    print_img(img, axs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    trainer = create_supervised_trainer(model, optimizer, loss_fn, device)\n",
    "\n",
    "    val_metrics = {\n",
    "        \"accuracy\": Accuracy(),\n",
    "        \"loss\": Loss(loss_fn)\n",
    "    }\n",
    "\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "    val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        train_evaluator.run(train_loader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(trainer):\n",
    "        val_evaluator.run(test_loader)\n",
    "        metrics = val_evaluator.state.metrics\n",
    "        print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "    def score_function(engine):\n",
    "        metrics = engine.state.metrics\n",
    "        return metrics[\"accuracy\"]\n",
    "    \n",
    "    val_evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(3, score_function, trainer))\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch[1] Avg accuracy: 52.72%, Avg loss: 1.34\n",
      "Validation Results - Epoch[1] Avg accuracy: 51.76%, Avg loss: 1.37\n",
      "Training Results - Epoch[2] Avg accuracy: 67.23%, Avg loss: 0.92\n",
      "Validation Results - Epoch[2] Avg accuracy: 65.31%, Avg loss: 0.99\n",
      "Training Results - Epoch[3] Avg accuracy: 71.24%, Avg loss: 0.82\n",
      "Validation Results - Epoch[3] Avg accuracy: 68.09%, Avg loss: 0.91\n",
      "Training Results - Epoch[4] Avg accuracy: 68.95%, Avg loss: 0.91\n",
      "Validation Results - Epoch[4] Avg accuracy: 65.14%, Avg loss: 1.04\n",
      "Training Results - Epoch[5] Avg accuracy: 76.54%, Avg loss: 0.68\n",
      "Validation Results - Epoch[5] Avg accuracy: 71.21%, Avg loss: 0.88\n",
      "Training Results - Epoch[6] Avg accuracy: 76.53%, Avg loss: 0.68\n",
      "Validation Results - Epoch[6] Avg accuracy: 70.72%, Avg loss: 0.90\n",
      "Training Results - Epoch[7] Avg accuracy: 82.52%, Avg loss: 0.49\n",
      "Validation Results - Epoch[7] Avg accuracy: 75.19%, Avg loss: 0.77\n",
      "Training Results - Epoch[8] Avg accuracy: 85.64%, Avg loss: 0.42\n",
      "Validation Results - Epoch[8] Avg accuracy: 75.77%, Avg loss: 0.74\n",
      "Training Results - Epoch[9] Avg accuracy: 88.32%, Avg loss: 0.34\n",
      "Validation Results - Epoch[9] Avg accuracy: 76.62%, Avg loss: 0.76\n",
      "Training Results - Epoch[10] Avg accuracy: 89.96%, Avg loss: 0.29\n",
      "Validation Results - Epoch[10] Avg accuracy: 77.70%, Avg loss: 0.72\n",
      "Training Results - Epoch[11] Avg accuracy: 91.20%, Avg loss: 0.26\n",
      "Validation Results - Epoch[11] Avg accuracy: 77.93%, Avg loss: 0.75\n",
      "Training Results - Epoch[12] Avg accuracy: 90.21%, Avg loss: 0.28\n",
      "Validation Results - Epoch[12] Avg accuracy: 76.45%, Avg loss: 0.85\n",
      "Training Results - Epoch[13] Avg accuracy: 93.68%, Avg loss: 0.19\n",
      "Validation Results - Epoch[13] Avg accuracy: 77.98%, Avg loss: 0.82\n",
      "Training Results - Epoch[14] Avg accuracy: 91.15%, Avg loss: 0.27\n",
      "Validation Results - Epoch[14] Avg accuracy: 75.91%, Avg loss: 0.95\n",
      "Training Results - Epoch[15] Avg accuracy: 94.27%, Avg loss: 0.17\n",
      "Validation Results - Epoch[15] Avg accuracy: 77.35%, Avg loss: 0.95\n",
      "Training Results - Epoch[16] Avg accuracy: 94.16%, Avg loss: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 18:35:43,775 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch[16] Avg accuracy: 77.53%, Avg loss: 0.96\n"
     ]
    }
   ],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_block(3, 64, True)\n",
    "        self.conv2 = conv_block(64, 128, True)\n",
    "        self.conv3 = conv_block(128, 128)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(self.conv3(x)) + x\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "model = Net().to(device)\n",
    "run_model(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 3 - Validation Results - Epoch[11] Avg accuracy: 55.59%, Avg loss: 1.34\n",
    "2 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.85%, Avg loss: 1.34\n",
    "\n",
    "3 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.77%, Avg loss: 1.23\n",
    "3 + 4 - Validation Results - Epoch[12] Avg accuracy: 61.44%, Avg loss: 1.42\n",
    "3 + 5 - Validation Results - Epoch[15] Avg accuracy: 57.74%, Avg loss: 1.47\n",
    "\n",
    "4 + 3 - Validation Results - Epoch[11] Avg accuracy: 59.61%, Avg loss: 1.36\n",
    "4 + 4 - Validation Results - Epoch[15] Avg accuracy: 61.82%, Avg loss: 1.52\n",
    "4 + 5 - Validation Results - Epoch[19] Avg accuracy: 60.91%, Avg loss: 1.24\n",
    "\n",
    "5 + 3 - Validation Results - Epoch[18] Avg accuracy: 60.97%, Avg loss: 1.17\n",
    "5 + 4 - Validation Results - Epoch[14] Avg accuracy: 60.22%, Avg loss: 1.24\n",
    "5 + 5 - Validation Results - Epoch[23] Avg accuracy: 61.34%, Avg loss: 1.33\n",
    "5 + 6 - Validation Results - Epoch[20] Avg accuracy: 59.16%, Avg loss: 1.23\n",
    "\n",
    "6 + 3 - Validation Results - Epoch[17] Avg accuracy: 60.48%, Avg loss: 1.22\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pooling\n",
    "2 + 2 - Validation Results - Epoch[16] Avg accuracy: 61.48%, Avg loss: 1.09\n",
    "2 + 3 - Validation Results - Epoch[19] Avg accuracy: 61.46%, Avg loss: 1.11\n",
    "2 + 4 - Validation Results - Epoch[17] Avg accuracy: 61.60%, Avg loss: 1.10\n",
    "2 + 5 - Validation Results - Epoch[17] Avg accuracy: 58.76%, Avg loss: 1.23\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[25] Avg accuracy: 63.66%, Avg loss: 1.10  # 3x3 kernel\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[65] Avg accuracy: 59.91%, Avg loss: 1.17  # sigmoid\n",
    "2 + 3 - Validation Results - Epoch[31] Avg accuracy: 56.99%, Avg loss: 1.21  # sigmoid\n",
    "2 + 4 - Validation Results - Epoch[40] Avg accuracy: 59.25%, Avg loss: 1.17  # sigmoid\n",
    "2 + 2 - Validation Results - Epoch[22] Avg accuracy: 52.06%, Avg loss: 1.33  # 3x3 kernel sigmoid\n",
    "\n",
    "3 + 4 - Validation Results - Epoch[15] Avg accuracy: 65.09%, Avg loss: 1.09  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[20] Avg accuracy: 65.20%, Avg loss: 1.11  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[22] Avg accuracy: 64.24%, Avg loss: 1.11  # 3v3 kernel, no pooling on last conv\n",
    "\n",
    "3 + 5 - Validation Results - Epoch[14] Avg accuracy: 71.76%, Avg loss: 0.91  # 3v3 kernel, no pooling on last conv, 3 -> 64 -> 128 -> 128 channels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Results - Epoch[11] Avg accuracy: 76.68%, Avg loss: 0.89  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c + 5 fc\n",
    "Validation Results - Epoch[14] Avg accuracy: 77.51%, Avg loss: 0.99  # j.w. + 4 fc, last with relu\n",
    "Validation Results - Epoch[11] Avg accuracy: 77.01%, Avg loss: 0.81  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c -- 3 conv + 5 fc, res on last conv\n",
    "Validation Results - Epoch[16] Avg accuracy: 77.53%, Avg loss: 0.96  # architecture from https://medium.com/analytics-vidhya/resnet-10f4ef1b9d4c -- 2 conv + res + 4 fc, res on last conv which is double (actually as in article)  -- left in model in commit\n",
    "Validation Results - Epoch[13] Avg accuracy: 67.98%, Avg loss: 1.30  # same as above but two res modules\n",
    "Validation Results - Epoch[12] Avg accuracy: 70.42%, Avg loss: 1.37  # 2 conv + res + 1 conv + 4 fc\n",
    "Validation Results - Epoch[10] Avg accuracy: 68.59%, Avg loss: 1.47  # 2 conv + res + 2 conv + res + 4 fc\n",
    "Validation Results - Epoch[11] Avg accuracy: 69.94%, Avg loss: 1.33  # 2 conv + res + 2 conv + res + 5 fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
