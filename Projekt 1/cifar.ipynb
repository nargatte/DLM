{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bez tego wysadza kernel kiedy rysuje obrazek\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a5e1dfb90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {\n",
    "    0: \"plane\",\n",
    "    1: \"car\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "batch_size = 64\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # this includes scaling to [0, 1]\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=True)\n",
    "test_data = datasets.CIFAR10(\"./cifar10\", download=True, transform=transform, train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(test_data)\n",
    "print(train_data[0][0].size())\n",
    "print(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(img, axs):\n",
    "    img_np = img.numpy()\n",
    "    img_denormalized = (img_np*255).astype(\"uint8\").transpose(1, 2, 0) \n",
    "    return axs.imshow(img_denormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 5, constrained_layout=True)\n",
    "axs = np.reshape(axs, -1)\n",
    "for x in range(15):\n",
    "    img, label = train_data[x]\n",
    "    axs[x].title.set_text(classes[label])\n",
    "    print_img(img, axs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    trainer = create_supervised_trainer(model, optimizer, loss_fn, device)\n",
    "\n",
    "    val_metrics = {\n",
    "        \"accuracy\": Accuracy(),\n",
    "        \"loss\": Loss(loss_fn)\n",
    "    }\n",
    "\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "    val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        train_evaluator.run(train_loader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(trainer):\n",
    "        val_evaluator.run(test_loader)\n",
    "        metrics = val_evaluator.state.metrics\n",
    "        print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy'] * 100:.2f}%, Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "    def score_function(engine):\n",
    "        metrics = engine.state.metrics\n",
    "        return metrics[\"accuracy\"]\n",
    "    \n",
    "    val_evaluator.add_event_handler(Events.COMPLETED, EarlyStopping(3, score_function, trainer))\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch[1] Avg accuracy: 34.45%, Avg loss: 1.67\n",
      "Validation Results - Epoch[1] Avg accuracy: 34.49%, Avg loss: 1.67\n",
      "Training Results - Epoch[2] Avg accuracy: 42.32%, Avg loss: 1.51\n",
      "Validation Results - Epoch[2] Avg accuracy: 42.17%, Avg loss: 1.52\n",
      "Training Results - Epoch[3] Avg accuracy: 48.83%, Avg loss: 1.40\n",
      "Validation Results - Epoch[3] Avg accuracy: 48.14%, Avg loss: 1.42\n",
      "Training Results - Epoch[4] Avg accuracy: 52.23%, Avg loss: 1.31\n",
      "Validation Results - Epoch[4] Avg accuracy: 51.28%, Avg loss: 1.33\n",
      "Training Results - Epoch[5] Avg accuracy: 57.18%, Avg loss: 1.19\n",
      "Validation Results - Epoch[5] Avg accuracy: 55.54%, Avg loss: 1.25\n",
      "Training Results - Epoch[6] Avg accuracy: 60.39%, Avg loss: 1.11\n",
      "Validation Results - Epoch[6] Avg accuracy: 58.15%, Avg loss: 1.18\n",
      "Training Results - Epoch[7] Avg accuracy: 60.29%, Avg loss: 1.10\n",
      "Validation Results - Epoch[7] Avg accuracy: 57.39%, Avg loss: 1.19\n",
      "Training Results - Epoch[8] Avg accuracy: 64.53%, Avg loss: 1.00\n",
      "Validation Results - Epoch[8] Avg accuracy: 60.07%, Avg loss: 1.12\n",
      "Training Results - Epoch[9] Avg accuracy: 64.15%, Avg loss: 1.01\n",
      "Validation Results - Epoch[9] Avg accuracy: 59.51%, Avg loss: 1.14\n",
      "Training Results - Epoch[10] Avg accuracy: 68.37%, Avg loss: 0.90\n",
      "Validation Results - Epoch[10] Avg accuracy: 63.05%, Avg loss: 1.06\n",
      "Training Results - Epoch[11] Avg accuracy: 69.47%, Avg loss: 0.87\n",
      "Validation Results - Epoch[11] Avg accuracy: 63.25%, Avg loss: 1.05\n",
      "Training Results - Epoch[12] Avg accuracy: 68.26%, Avg loss: 0.89\n",
      "Validation Results - Epoch[12] Avg accuracy: 61.93%, Avg loss: 1.10\n",
      "Training Results - Epoch[13] Avg accuracy: 70.87%, Avg loss: 0.83\n",
      "Validation Results - Epoch[13] Avg accuracy: 63.36%, Avg loss: 1.06\n",
      "Training Results - Epoch[14] Avg accuracy: 73.25%, Avg loss: 0.76\n",
      "Validation Results - Epoch[14] Avg accuracy: 64.15%, Avg loss: 1.03\n",
      "Training Results - Epoch[15] Avg accuracy: 74.14%, Avg loss: 0.74\n",
      "Validation Results - Epoch[15] Avg accuracy: 64.49%, Avg loss: 1.04\n",
      "Training Results - Epoch[16] Avg accuracy: 74.92%, Avg loss: 0.72\n",
      "Validation Results - Epoch[16] Avg accuracy: 64.90%, Avg loss: 1.04\n",
      "Training Results - Epoch[17] Avg accuracy: 75.78%, Avg loss: 0.69\n",
      "Validation Results - Epoch[17] Avg accuracy: 64.10%, Avg loss: 1.06\n",
      "Training Results - Epoch[18] Avg accuracy: 76.22%, Avg loss: 0.68\n",
      "Validation Results - Epoch[18] Avg accuracy: 63.59%, Avg loss: 1.07\n",
      "Training Results - Epoch[19] Avg accuracy: 78.00%, Avg loss: 0.63\n",
      "Validation Results - Epoch[19] Avg accuracy: 64.96%, Avg loss: 1.07\n",
      "Training Results - Epoch[20] Avg accuracy: 78.80%, Avg loss: 0.61\n",
      "Validation Results - Epoch[20] Avg accuracy: 64.73%, Avg loss: 1.08\n",
      "Training Results - Epoch[21] Avg accuracy: 77.83%, Avg loss: 0.63\n",
      "Validation Results - Epoch[21] Avg accuracy: 63.56%, Avg loss: 1.15\n",
      "Training Results - Epoch[22] Avg accuracy: 80.23%, Avg loss: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 15:37:59,044 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch[22] Avg accuracy: 64.24%, Avg loss: 1.11\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        # self.conv4 = nn.Conv2d(32, 48, 5)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 120)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # self.fc1 = nn.Linear(6 * 28 * 28, 120)\n",
    "        # self.fc1 = nn.Linear(32 * 16 * 16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.conv3(x)\n",
    "        # x = self.pool(F.relu(self.conv3(x)))\n",
    "        # x = self.pool(F.relu(self.conv4(x)))\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # x = F.relu(self.conv2(x))\n",
    "        # x = F.relu(self.conv3(x))\n",
    "        # x = F.relu(self.conv4(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "model = Net().to(device)\n",
    "run_model(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 3 - Validation Results - Epoch[11] Avg accuracy: 55.59%, Avg loss: 1.34\n",
    "2 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.85%, Avg loss: 1.34\n",
    "\n",
    "3 + 3 - Validation Results - Epoch[10] Avg accuracy: 58.77%, Avg loss: 1.23\n",
    "3 + 4 - Validation Results - Epoch[12] Avg accuracy: 61.44%, Avg loss: 1.42\n",
    "3 + 5 - Validation Results - Epoch[15] Avg accuracy: 57.74%, Avg loss: 1.47\n",
    "\n",
    "4 + 3 - Validation Results - Epoch[11] Avg accuracy: 59.61%, Avg loss: 1.36\n",
    "4 + 4 - Validation Results - Epoch[15] Avg accuracy: 61.82%, Avg loss: 1.52\n",
    "4 + 5 - Validation Results - Epoch[19] Avg accuracy: 60.91%, Avg loss: 1.24\n",
    "\n",
    "5 + 3 - Validation Results - Epoch[18] Avg accuracy: 60.97%, Avg loss: 1.17\n",
    "5 + 4 - Validation Results - Epoch[14] Avg accuracy: 60.22%, Avg loss: 1.24\n",
    "5 + 5 - Validation Results - Epoch[23] Avg accuracy: 61.34%, Avg loss: 1.33\n",
    "5 + 6 - Validation Results - Epoch[20] Avg accuracy: 59.16%, Avg loss: 1.23\n",
    "\n",
    "6 + 3 - Validation Results - Epoch[17] Avg accuracy: 60.48%, Avg loss: 1.22\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pooling\n",
    "2 + 2 - Validation Results - Epoch[16] Avg accuracy: 61.48%, Avg loss: 1.09\n",
    "2 + 3 - Validation Results - Epoch[19] Avg accuracy: 61.46%, Avg loss: 1.11\n",
    "2 + 4 - Validation Results - Epoch[17] Avg accuracy: 61.60%, Avg loss: 1.10\n",
    "2 + 5 - Validation Results - Epoch[17] Avg accuracy: 58.76%, Avg loss: 1.23\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[25] Avg accuracy: 63.66%, Avg loss: 1.10  # 3x3 kernel\n",
    "\n",
    "2 + 2 - Validation Results - Epoch[65] Avg accuracy: 59.91%, Avg loss: 1.17  # sigmoid\n",
    "2 + 3 - Validation Results - Epoch[31] Avg accuracy: 56.99%, Avg loss: 1.21  # sigmoid\n",
    "2 + 4 - Validation Results - Epoch[40] Avg accuracy: 59.25%, Avg loss: 1.17  # sigmoid\n",
    "2 + 2 - Validation Results - Epoch[22] Avg accuracy: 52.06%, Avg loss: 1.33  # 3x3 kernel sigmoid\n",
    "\n",
    "3 + 4 - Validation Results - Epoch[15] Avg accuracy: 65.09%, Avg loss: 1.09  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[20] Avg accuracy: 65.20%, Avg loss: 1.11  # 3x3 kernel, no pooling on last conv, no relu between conv and pool\n",
    "3 + 5 - Validation Results - Epoch[22] Avg accuracy: 64.24%, Avg loss: 1.11  # 3v3 kernel, no pooling on last conv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
